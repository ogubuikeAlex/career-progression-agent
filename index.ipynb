{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52b864b",
   "metadata": {},
   "source": [
    "# Exploitation 0001 - January 06 26\n",
    "\n",
    "## Goal: I am creating an agent that I will exploit.\n",
    "\n",
    "This agent will take in a resume and recommend what the resume owner needs to learn to become relevant in the AI Era.\n",
    "\n",
    "To start, I will install initialize my LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a164cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY') or getpass('Enter Open Ai API KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c065d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_model = 'gpt-4o-mini'\n",
    "llm = ChatOpenAI(temperature=0.0, model=openai_model)\n",
    "\n",
    "creative_llm = ChatOpenAI(temperature=0.9, model=openai_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be5b12",
   "metadata": {},
   "source": [
    "The next thing we will do is to prepare our prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c000450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "resume = '''\n",
    "Experience: 6+ years as a backend or full-stack engineer building web applications\n",
    "Python/Django: 3+ years of experience with Python and Django\n",
    "Frameworks: Django REST Framework and/or django-ninja\n",
    "Scalability: Proven experience running Django at scale\n",
    "Asynchronous Systems: Celery, RabbitMQ, Redis\n",
    "Databases: Postgres and NoSQL (Elasticsearch, MongoDB, Cassandra)\n",
    "Infrastructure: Kubernetes, microservices, resource management\n",
    "Cloud: AWS preferred; GCP or Azure acceptable\n",
    "Frontend: Working knowledge of HTML and JavaScript\n",
    "Bonus: React, HTMX, automation tools, or consumer privacy industry experience\n",
    "'''\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template('You are an AI Career Expert. You Review Resumes and Help To Tell People What To Learn To Be Relevant in The AI Era')\n",
    "\n",
    "user_prompt = HumanMessagePromptTemplate.from_template('''\n",
    "You are tasked with giving career advice based on a resume. \n",
    "The resume is found here {resume}\n",
    "\n",
    "The career advice should be very specific to the resume submitted.\n",
    "Ensure you answer is always limited to 100 words only\n",
    "The advice should show skills, technologies and 3 possible job roles the owner of the resume should get to be relevant in the AI Era.\n",
    "Only output the career advice and no other explanation or text can be provided.\n",
    "''', \n",
    "                                            input_variable='resume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ac4f5",
   "metadata": {},
   "source": [
    "The next thing is for us to check if the input variable actually works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a884f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='\\nYou are tasked with giving career advice based on a resume. \\nThe resume is found here Software Engineer With 6 Years Of Experience\\n\\nThe career advice should be very specific to the resume submitted.\\nEnsure you answer is always limited to 100 words only\\nThe advice should show skills, technologies and 3 possible job roles the owner of the resume should get to be relevant in the AI Era.\\nOnly output the career advice and no other explanation or text can be provided.\\n', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt.format(resume='Software Engineer With 6 Years Of Experience')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a743f58",
   "metadata": {},
   "source": [
    "Since we have the system and user prompts, the next thing for us to do is to create the chat prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f453a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an AI Career Expert. You Review Resumes and Help To Tell People What To Learn To Be Relevant in The AI Era\n",
      "Human: \n",
      "You are tasked with giving career advice based on a resume. \n",
      "The resume is found here Software Engineer With 6 Years Of Experience\n",
      "\n",
      "The career advice should be very specific to the resume submitted.\n",
      "Ensure you answer is always limited to 100 words only\n",
      "The advice should show skills, technologies and 3 possible job roles the owner of the resume should get to be relevant in the AI Era.\n",
      "Only output the career advice and no other explanation or text can be provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])\n",
    "\n",
    "# Test Out What Our First Prompt Is\n",
    "print(first_prompt.format(resume='Software Engineer With 6 Years Of Experience'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4943b3f",
   "metadata": {},
   "source": [
    "The next thing is for us to combine the first_prompt we have with the llm we created to an LLM Chain\n",
    "\n",
    "## What is An LLM Chain?\n",
    "This is a simple step-by-step work flow where you drop and input and the input is sent to an LLM via a prompt. The LLM's out put is then formatted, transformed, passed into another step or another LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd6548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = (\n",
    "    {'resume': lambda x: x['resume']}\n",
    "    | first_prompt\n",
    "    | creative_llm\n",
    "    | {'final_advice': lambda x : x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b154324",
   "metadata": {},
   "source": [
    "Now we have created the Lang Chain Expression Language. Let Us Invoke It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "advice = chain_one.invoke({'resume': resume})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
